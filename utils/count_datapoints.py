import pandas as pd
from datetime import datetime, timedelta
import os
import glob
from pathlib import Path

def count_datapoints_in_folders(base_directory):
    """
    train, val, test í´ë” ë‚´ CSV íŒŒì¼ë“¤ì˜ ë°ì´í„° í¬ì¸íŠ¸ ê°œìˆ˜ë¥¼ ê³„ì‚°
    
    Parameters:
    base_directory (str): train, val, test í´ë”ê°€ ìˆëŠ” ìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    
    base_path = Path(base_directory)
    
    # í´ë”ë³„ ê²°ê³¼ ì €ì¥
    folder_stats = {}
    
    # train, val, test í´ë” ìˆœíšŒ
    for folder_name in ['train', 'val', 'test']:
        folder_path = base_path / folder_name
    # for folder_name in ['train', 'test']:
    #     folder_path = base_path / folder_name
        
        if not folder_path.exists():
            print(f"âš ï¸ {folder_name} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
            continue
        
        print(f"\n=== {folder_name.upper()} í´ë” ë¶„ì„ ===")
        print(f"ê²½ë¡œ: {folder_path}")
        
        # CSV íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
        
        if not csv_files:
            print(f"CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            folder_stats[folder_name] = {'files': 0, 'total_rows': 0, 'file_details': []}
            continue
        
        csv_files.sort()  # íŒŒì¼ëª… ì •ë ¬
        
        total_rows = 0
        file_details = []
        
        for csv_file in csv_files:
            try:
                file_path = folder_path / csv_file
                df = pd.read_csv(file_path)
                rows = len(df)
                total_rows += rows
                
                file_details.append({
                    'filename': csv_file,
                    'rows': rows
                })
                
                print(f"  {csv_file}: {rows:,} rows")
                
            except Exception as e:
                print(f"  âŒ {csv_file}: ì˜¤ë¥˜ ë°œìƒ - {str(e)}")
                file_details.append({
                    'filename': csv_file,
                    'rows': 0,
                    'error': str(e)
                })
        
        folder_stats[folder_name] = {
            'files': len(csv_files),
            'total_rows': total_rows,
            'file_details': file_details
        }
        
        print(f"\nğŸ“Š {folder_name} í´ë” ìš”ì•½:")
        print(f"  - íŒŒì¼ ìˆ˜: {len(csv_files)}ê°œ")
        print(f"  - ì´ ë°ì´í„° í¬ì¸íŠ¸: {total_rows:,}ê°œ")
        print(f"  - í‰ê·  ë°ì´í„° í¬ì¸íŠ¸/íŒŒì¼: {total_rows/len(csv_files):.0f}ê°œ")
    
    return folder_stats

def print_summary_table(folder_stats):
    """
    ì „ì²´ ìš”ì•½ í…Œì´ë¸” ì¶œë ¥
    """
    print("\n" + "="*60)
    print("ğŸ“‹ ì „ì²´ ìš”ì•½")
    print("="*60)
    
    # í…Œì´ë¸” í—¤ë”
    print(f"{'í´ë”':<10} {'íŒŒì¼ ìˆ˜':<10} {'ì´ ë°ì´í„° í¬ì¸íŠ¸':<15} {'í‰ê· /íŒŒì¼':<12}")
    print("-" * 60)
    
    total_files = 0
    total_datapoints = 0
    
    for folder_name, stats in folder_stats.items():
        files = stats['files']
        rows = stats['total_rows']
        avg = rows / files if files > 0 else 0
        
        total_files += files
        total_datapoints += rows
        
        print(f"{folder_name:<10} {files:<10} {rows:<15,} {avg:<12.0f}")
    
    print("-" * 60)
    print(f"{'TOTAL':<10} {total_files:<10} {total_datapoints:<15,} {total_datapoints/total_files if total_files > 0 else 0:<12.0f}")
    
    # ë¹„ìœ¨ ê³„ì‚°
    if total_datapoints > 0:
        print(f"\nğŸ“ˆ ë°ì´í„° ë¶„í•  ë¹„ìœ¨:")
        for folder_name, stats in folder_stats.items():
            ratio = (stats['total_rows'] / total_datapoints) * 100
            print(f"  {folder_name}: {ratio:.1f}%")


def find_missing_dates(file_path, timestamp_column='timestamp'):
    """
    CSV íŒŒì¼ì—ì„œ ë¹ ì§„ ë‚ ì§œë¥¼ ì°¾ëŠ” í•¨ìˆ˜
    
    Parameters:
    file_path (str): CSV íŒŒì¼ ê²½ë¡œ
    timestamp_column (str): ë‚ ì§œ ì»¬ëŸ¼ëª…
    """
    try:
        # CSV íŒŒì¼ ì½ê¸°
        df = pd.read_csv(file_path)
        
        if timestamp_column not in df.columns:
            print(f"ì˜¤ë¥˜: '{timestamp_column}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
            return None
        
        # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        df[timestamp_column] = pd.to_datetime(df[timestamp_column])
        
        # ë‚ ì§œë§Œ ì¶”ì¶œ (ì‹œê°„ ì œê±°)
        df['date_only'] = df[timestamp_column].dt.date
        
        # ê³ ìœ í•œ ë‚ ì§œë“¤ë§Œ ì¶”ì¶œí•˜ê³  ì •ë ¬
        unique_dates = sorted(df['date_only'].unique())
        
        # ì „ì²´ ê¸°ê°„ì—ì„œ ì—°ì†ëœ ë‚ ì§œ ìƒì„±
        start_date = min(unique_dates)
        end_date = max(unique_dates)
        
        # ì—°ì†ëœ ëª¨ë“  ë‚ ì§œ ìƒì„±
        date_range = pd.date_range(start=start_date, end=end_date, freq='D').date
        
        # ë¹ ì§„ ë‚ ì§œë“¤ ì°¾ê¸°
        missing_dates = [date for date in date_range if date not in unique_dates]
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n=== íŒŒì¼: {os.path.basename(file_path)} ===")
        print(f"ë°ì´í„° ê¸°ê°„: {start_date} ~ {end_date}")
        print(f"ì „ì²´ ê¸°ê°„: {len(date_range)}ì¼")
        print(f"ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ: {len(unique_dates)}ì¼")
        print(f"ë¹ ì§„ ë‚ ì§œ ìˆ˜: {len(missing_dates)}ì¼")
        
        if missing_dates:
            print(f"\në¹ ì§„ ë‚ ì§œë“¤:")
            for i, missing_date in enumerate(missing_dates, 1):
                print(f"  {i:3d}. {missing_date}")
                
            # ì—°ì†ëœ ë¹ ì§„ ë‚ ì§œ êµ¬ê°„ ì°¾ê¸°
            consecutive_gaps = find_consecutive_gaps(missing_dates)
            if consecutive_gaps:
                print(f"\nì—°ì†ìœ¼ë¡œ ë¹ ì§„ ë‚ ì§œ êµ¬ê°„:")
                for gap in consecutive_gaps:
                    if gap['start'] == gap['end']:
                        print(f"  - {gap['start']} (1ì¼)")
                    else:
                        print(f"  - {gap['start']} ~ {gap['end']} ({gap['days']}ì¼)")
        else:
            print("âœ… ë¹ ì§„ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤!")
        
        return {
            'missing_dates': missing_dates,
            'total_days': len(date_range),
            'actual_days': len(unique_dates),
            'missing_count': len(missing_dates),
            'start_date': start_date,
            'end_date': end_date
        }
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def find_consecutive_gaps(missing_dates):
    """
    ì—°ì†ëœ ë¹ ì§„ ë‚ ì§œ êµ¬ê°„ì„ ì°¾ëŠ” í•¨ìˆ˜
    """
    if not missing_dates:
        return []
    
    gaps = []
    current_start = missing_dates[0]
    current_end = missing_dates[0]
    
    for i in range(1, len(missing_dates)):
        # ì´ì „ ë‚ ì§œì™€ ì—°ì†ì¸ì§€ í™•ì¸
        if missing_dates[i] == current_end + timedelta(days=1):
            current_end = missing_dates[i]
        else:
            # ì—°ì†ì´ ëŠì–´ì§, í˜„ì¬ êµ¬ê°„ ì €ì¥
            gaps.append({
                'start': current_start,
                'end': current_end,
                'days': (current_end - current_start).days + 1
            })
            current_start = missing_dates[i]
            current_end = missing_dates[i]
    
    # ë§ˆì§€ë§‰ êµ¬ê°„ ì €ì¥
    gaps.append({
        'start': current_start,
        'end': current_end,
        'days': (current_end - current_start).days + 1
    })
    
    return gaps

def analyze_directory(directory_path, timestamp_column='timestamp'):
    """
    ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  CSV íŒŒì¼ì˜ ë¹ ì§„ ë‚ ì§œ ë¶„ì„
    
    Parameters:
    directory_path (str): CSV íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
    timestamp_column (str): ë‚ ì§œ ì»¬ëŸ¼ëª…
    """
    csv_files = glob.glob(os.path.join(directory_path, "*.csv"))
    
    if not csv_files:
        print(f"ë””ë ‰í† ë¦¬ '{directory_path}'ì—ì„œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    print("="*60)
    
    all_results = {}
    
    for file_path in csv_files:
        result = find_missing_dates(file_path, timestamp_column)
        if result:
            all_results[os.path.basename(file_path)] = result
    
    # ì „ì²´ ìš”ì•½ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ì „ì²´ ìš”ì•½")
    print("="*60)
    
    if all_results:
        print(f"{'íŒŒì¼ëª…':<30} {'ì „ì²´ì¼ìˆ˜':<8} {'ì‹¤ì œì¼ìˆ˜':<8} {'ë¹ ì§„ì¼ìˆ˜':<8} {'ë¹„ìœ¨':<8}")
        print("-" * 70)
        
        total_expected = 0
        total_actual = 0
        total_missing = 0
        
        for filename, result in all_results.items():
            ratio = (result['missing_count'] / result['total_days']) * 100
            print(f"{filename[:29]:<30} {result['total_days']:<8} {result['actual_days']:<8} {result['missing_count']:<8} {ratio:<7.1f}%")
            
            total_expected += result['total_days']
            total_actual += result['actual_days']
            total_missing += result['missing_count']
        
        print("-" * 70)
        overall_ratio = (total_missing / total_expected) * 100 if total_expected > 0 else 0
        print(f"{'ì „ì²´ í•©ê³„':<30} {total_expected:<8} {total_actual:<8} {total_missing:<8} {overall_ratio:<7.1f}%")

def save_missing_dates_report(directory_path, output_file="missing_dates_report.csv", timestamp_column='timestamp'):
    """
    ë¹ ì§„ ë‚ ì§œ ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    """
    csv_files = glob.glob(os.path.join(directory_path, "*.csv"))
    
    report_data = []
    
    for file_path in csv_files:
        result = find_missing_dates(file_path, timestamp_column)
        if result and result['missing_dates']:
            for missing_date in result['missing_dates']:
                report_data.append({
                    'filename': os.path.basename(file_path),
                    'missing_date': missing_date,
                    'start_date': result['start_date'],
                    'end_date': result['end_date']
                })
    
    if report_data:
        report_df = pd.DataFrame(report_data)
        report_df.to_csv(output_file, index=False)
        print(f"\nğŸ’¾ ë¹ ì§„ ë‚ ì§œ ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")
    else:
        print("\nâœ… ëª¨ë“  íŒŒì¼ì— ë¹ ì§„ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤!")


def save_detailed_report(folder_stats, output_file="datapoint_report.csv"):
    """
    ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    """
    report_data = []
    
    for folder_name, stats in folder_stats.items():
        for file_detail in stats['file_details']:
            report_data.append({
                'folder': folder_name,
                'filename': file_detail['filename'],
                'rows': file_detail.get('rows', 0),
                'error': file_detail.get('error', '')
            })
    
    report_df = pd.DataFrame(report_data)
    report_df.to_csv(output_file, index=False)
    print(f"\nğŸ’¾ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")
    
    return report_df

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì • (train, val, test í´ë”ê°€ ìˆëŠ” ìƒìœ„ ê²½ë¡œ)
    base_directory = "/home/bak/Projects/pv-power-forecasting/data/GISTchrono/processed_data_split/"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”
    # base_directory = "/home/bak/Projects/pv-power-forecasting/data/Germanychrono/processed_data_split/"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”
    
    # ë°ì´í„° í¬ì¸íŠ¸ ê°œìˆ˜ ê³„ì‚°
    stats = count_datapoints_in_folders(base_directory)
    
    # ìš”ì•½ í…Œì´ë¸” ì¶œë ¥
    print_summary_table(stats)
    dir_path = os.path.join(base_directory, "test")  # test í´ë” ê²½ë¡œ
    analyze_directory(dir_path, "timestamp")

    # ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥
    # save_detailed_report(stats)
    # save_missing_dates_report(directory_path, "missing_dates_report.csv", "timestamp")